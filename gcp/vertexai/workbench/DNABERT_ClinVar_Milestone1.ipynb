{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b491aab-bc4f-4a2d-85cf-ae893265d748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Cleanup these first three blocks. Consolidate\n",
    "# Uncomment as needed in your runtime (internet required)\n",
    "%pip install -q transformers datasets peft accelerate scikit-learn matplotlib seaborn \\\n",
    "              pyfaidx google-cloud-storage cyvcf2\n",
    "\n",
    "# If using CUDA:\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "     print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9e05b-260f-46f2-9a98-2f42a4ba4c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-time fixing packages\n",
    "%pip install -U \"transformers>=4.44.2\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \"datasets>=2.20\"\n",
    "\n",
    "import transformers, torch\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2420290d-553b-44f4-b127-199447abaee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-time fix for transformers version\n",
    "\n",
    "%pip uninstall -y transformers\n",
    "%pip install \"transformers==4.44.2\"  # known-good, definitely has evaluation_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b45fa0bc-ef6e-4df0-91fe-e0924051770c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, urllib.request, gzip, shutil, pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfea8aa-a3d6-4a49-ae2b-76e6a3890861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists: ./data/clinvar.vcf.gz\n",
      "Exists: ./data/clinvar.vcf.gz.tbi\n",
      "DATA_DIR: ./data\n",
      "VCF ready: True Index ready: True\n"
     ]
    }
   ],
   "source": [
    "# Download ClinVar\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"./data\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Download ClinVar GRCh38 VCF + index\n",
    "vcf_url  = \"https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz\"\n",
    "tbi_url  = \"https://ftp.ncbi.nlm.nih.gov/pub/clinvar/vcf_GRCh38/clinvar.vcf.gz.tbi\"\n",
    "vcf_path = os.path.join(DATA_DIR, \"clinvar.vcf.gz\")\n",
    "tbi_path = os.path.join(DATA_DIR, \"clinvar.vcf.gz.tbi\")\n",
    "\n",
    "def _dl(url, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"Downloading {url} -> {dest}\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "    else:\n",
    "        print(f\"Exists: {dest}\")\n",
    "\n",
    "_dl(vcf_url, vcf_path)\n",
    "_dl(tbi_url, tbi_path)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"VCF ready:\", os.path.exists(vcf_path), \"Index ready:\", os.path.exists(tbi_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df4638-0d14-4bbd-bed7-9d02f9a6e8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter ClinVar dataset\n",
    "from cyvcf2 import VCF\n",
    "import re, csv\n",
    "\n",
    "# ----- Configs -----\n",
    "out_csv = os.path.join(DATA_DIR, \"clinvar_snvs_clean.csv\")\n",
    "\n",
    "# Map CLNSIG to binary label (1 = pathogenic, 0 = benign); drop everything else\n",
    "pat_re = re.compile(r\"(Pathogenic|Likely_pathogenic)\", re.IGNORECASE)\n",
    "ben_re = re.compile(r\"(Benign|Likely_benign)\", re.IGNORECASE)\n",
    "\n",
    "# Optional: keep only higher-confidence review statuses (set to False to keep all)\n",
    "HIGH_CONF_ONLY = True\n",
    "good_rev = {\n",
    "    \"criteria_provided,_multiple_submitters,_no_conflicts\",\n",
    "    \"reviewed_by_expert_panel\",\n",
    "    \"practice_guideline\",\n",
    "}\n",
    "\n",
    "# Parse\n",
    "vcf = VCF(vcf_path)\n",
    "rows = []\n",
    "kept, skipped_sig, skipped_len, skipped_conf = 0,0,0,0\n",
    "\n",
    "for rec in vcf:\n",
    "    # SNVs only\n",
    "    if not rec.is_snp:\n",
    "        continue\n",
    "\n",
    "    clnsig = (rec.INFO.get(\"CLNSIG\") or \"\").replace(\" \", \"_\")\n",
    "    rev    = (rec.INFO.get(\"CLNREVSTAT\") or \"\").replace(\" \", \"_\")\n",
    "    gene   = (rec.INFO.get(\"GENEINFO\") or \"\")\n",
    "\n",
    "    # Binary label mapping\n",
    "    is_pat = bool(pat_re.search(clnsig))\n",
    "    is_ben = bool(ben_re.search(clnsig))\n",
    "    if not (is_pat or is_ben):\n",
    "        skipped_sig += 1\n",
    "        continue\n",
    "    label = 1 if is_pat else 0\n",
    "\n",
    "    # Optional high-confidence filter\n",
    "    if HIGH_CONF_ONLY:\n",
    "        # allow any record whose CLNREVSTAT contains at least one \"good\" tag\n",
    "        rv = rev.lower()\n",
    "        if not any(tag in rv for tag in good_rev):\n",
    "            skipped_conf += 1\n",
    "            continue\n",
    "\n",
    "    # Split multi-allelics; keep only 1bp ref/alt (pure SNVs)\n",
    "    for alt in rec.ALT or []:\n",
    "        if len(rec.REF) != 1 or len(alt) != 1:\n",
    "            skipped_len += 1\n",
    "            continue\n",
    "\n",
    "        rows.append({\n",
    "            \"CHROM\":   rec.CHROM,      # typically '1'..'22','X','Y','MT'\n",
    "            \"POS\":     rec.POS,        # 1-based\n",
    "            \"REF\":     rec.REF,\n",
    "            \"ALT\":     alt,\n",
    "            \"CLNSIG\":  clnsig,\n",
    "            \"CLNREV\":  rev,\n",
    "            \"GENEINFO\":gene,\n",
    "            \"LABEL\":   label           # 1=Pathogenic/Likely_pathogenic, 0=Benign/Likely_benign\n",
    "        })\n",
    "        kept += 1\n",
    "\n",
    "print(f\"Kept SNVs: {kept} | dropped (no binary CLNSIG): {skipped_sig} | \"\n",
    "      f\"dropped (non-1bp alleles): {skipped_len} | dropped (low-conf rev): {skipped_conf}\")\n",
    "\n",
    "# De-duplicate exact (CHROM,POS,REF,ALT) if desired\n",
    "df = pd.DataFrame(rows).drop_duplicates(subset=[\"CHROM\",\"POS\",\"REF\",\"ALT\"])\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv, \"Rows:\", len(df))\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Label counts:\\n\", df[\"LABEL\"].value_counts())\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a23183-fd44-4138-813f-2ae80ac7e698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print Chromosome counts\n",
    "df[\"CHROM\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a46c2-541b-4f3c-8c8a-6c8e66a7c46a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Reference\n",
    "import os, urllib.request, gzip, shutil\n",
    "\n",
    "REF_DIR = os.path.join(\".\", \"ref\")\n",
    "os.makedirs(REF_DIR, exist_ok=True)\n",
    "\n",
    "# UCSC hg38 (chr1..chr22, chrX, chrY, chrM) — good match for your CHROM values after mapping MT->chrM\n",
    "hg38_url = \"https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz\"\n",
    "fa_gz    = os.path.join(REF_DIR, \"hg38.fa.gz\")\n",
    "fa_path  = os.path.join(REF_DIR, \"hg38.fa\")\n",
    "\n",
    "def _dl(url, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"Downloading {url} -> {dest}\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "    else:\n",
    "        print(f\"Exists: {dest}\")\n",
    "\n",
    "# Download and gunzip (first time only)\n",
    "_dl(hg38_url, fa_gz)\n",
    "if not os.path.exists(fa_path):\n",
    "    print(f\"Unzipping {fa_gz} -> {fa_path} (this can take a few minutes)\")\n",
    "    with gzip.open(fa_gz, \"rb\") as f_in, open(fa_path, \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "else:\n",
    "    print(f\"Exists: {fa_path}\")\n",
    "\n",
    "print(\"Reference ready:\", os.path.exists(fa_path), \"| size (GB) ~\", round(os.path.getsize(fa_path)/1e9, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30ad5e-1d72-4b29-9f96-fad7824d91e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ClinVar SNVs and Normalize Chrom Names (robust dtype handling)\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"./data\")\n",
    "src_csv  = os.path.join(DATA_DIR, \"clinvar_snvs_clean.csv\")\n",
    "assert os.path.exists(src_csv), f\"Missing: {src_csv} (run the VCF parsing step first).\"\n",
    "\n",
    "# 1) Read as strings to avoid mixed-type inference warnings, then coerce numerics\n",
    "df = pd.read_csv(\n",
    "    src_csv,\n",
    "    dtype=str,            # read everything as string first\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Clean up any accidental index column\n",
    "for idx_col in [\"Unnamed: 0\", \"index\"]:\n",
    "    if idx_col in df.columns:\n",
    "        df = df.drop(columns=[idx_col])\n",
    "\n",
    "# Strip column-name whitespace just in case\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# 2) Coerce numeric columns\n",
    "for col, dtype in [(\"POS\", \"Int64\"), (\"LABEL\", \"Int8\")]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(dtype)\n",
    "\n",
    "# 3) Normalize chromosome names to UCSC FASTA names\n",
    "def normalize_chr(chrom: str) -> str:\n",
    "    \"\"\"\n",
    "    Map ClinVar CHROM values to UCSC FASTA names:\n",
    "      '1' -> 'chr1', ..., '22' -> 'chr22', 'X' -> 'chrX', 'Y' -> 'chrY', 'MT' -> 'chrM'\n",
    "    If already 'chr*', leave as is.\n",
    "    \"\"\"\n",
    "    if chrom is None or pd.isna(chrom):\n",
    "        return chrom\n",
    "    c = str(chrom).strip()\n",
    "    if not c.startswith(\"chr\"):\n",
    "        c = \"chr\" + c\n",
    "    if c == \"chrMT\":\n",
    "        c = \"chrM\"\n",
    "    return c\n",
    "\n",
    "df[\"CHR_UCSC\"] = df[\"CHROM\"].apply(normalize_chr)\n",
    "\n",
    "print(df[[\"CHROM\", \"CHR_UCSC\"]].head())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8d577-d583-45c8-a837-3b89c006cc4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract REF/ALT windows (+- FLANK) with pyfaidx\n",
    "from pyfaidx import Fasta\n",
    "import numpy as np\n",
    "\n",
    "# configurable flank (±N bp)\n",
    "FLANK = 100  # try 50/100/200 as experiments\n",
    "MAX_ROWS = None  # e.g., set to 5000 for a quick test\n",
    "\n",
    "fa = Fasta(os.path.join(\"ref\",\"hg38.fa\"), as_raw=True, build_index=True)\n",
    "\n",
    "def fetch_windows(row, flank=FLANK):\n",
    "    \"\"\"\n",
    "    Returns (ref_window, alt_window) around POS for 1bp REF->ALT.\n",
    "    Performs a quick sanity check that reference base matches FASTA.\n",
    "    \"\"\"\n",
    "    chrom = row[\"CHR_UCSC\"]\n",
    "    pos   = int(row[\"POS\"])            # 1-based\n",
    "    ref   = str(row[\"REF\"])\n",
    "    alt   = str(row[\"ALT\"])\n",
    "\n",
    "    # window coordinates inclusive [start, end], 1-based for pyfaidx slicing\n",
    "    start = max(1, pos - flank)\n",
    "    end   = pos + flank\n",
    "\n",
    "    try:\n",
    "        window = fa[chrom][start:end]  # string slice from FASTA\n",
    "    except KeyError:\n",
    "        # chromosome absent in FASTA (shouldn't happen with UCSC hg38)\n",
    "        return None, None\n",
    "\n",
    "    window = str(window).upper()\n",
    "    # check the reference base at center (index relative to 'start')\n",
    "    center_idx = pos - start\n",
    "    if center_idx < 0 or center_idx >= len(window):\n",
    "        return None, None\n",
    "\n",
    "    # confirm the base matches expectation\n",
    "    if window[center_idx] != ref.upper():\n",
    "        # Sometimes reference mismatch can occur due to liftover/outdated positions.\n",
    "        # For now, skip mismatches to keep dataset clean.\n",
    "        return None, None\n",
    "\n",
    "    # build alt window by substituting at the center position\n",
    "    alt_window = window[:center_idx] + alt.upper() + window[center_idx+1:]\n",
    "\n",
    "    return window, alt_window\n",
    "\n",
    "# Apply (optionally on a subset for speed testing)\n",
    "work_df = df if MAX_ROWS is None else df.head(MAX_ROWS).copy()\n",
    "\n",
    "ref_windows, alt_windows = [], []\n",
    "skipped = 0\n",
    "\n",
    "for i, row in work_df.iterrows():\n",
    "    r, a = fetch_windows(row, FLANK)\n",
    "    if r is None or a is None:\n",
    "        ref_windows.append(np.nan)\n",
    "        alt_windows.append(np.nan)\n",
    "        skipped += 1\n",
    "    else:\n",
    "        ref_windows.append(r)\n",
    "        alt_windows.append(a)\n",
    "\n",
    "work_df[\"ref_seq\"] = ref_windows\n",
    "work_df[\"alt_seq\"] = alt_windows\n",
    "work_df = work_df.dropna(subset=[\"ref_seq\",\"alt_seq\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Built windows for {len(work_df)} variants; skipped {skipped} due to chromosome/position mismatches.\")\n",
    "print(work_df[[\"CHROM\",\"POS\",\"REF\",\"ALT\",\"LABEL\",\"ref_seq\",\"alt_seq\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cefc09-8025-46d0-ac23-0a310d6d38fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save ready-to-tokenize dataset\n",
    "out_csv = os.path.join(DATA_DIR, f\"clinvar_seq_pairs_flank{FLANK}.csv\")\n",
    "work_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv, \"| rows:\", len(work_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7cc993-79cb-45a8-a22c-d9c6ddd0bc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Out of ~318 k ClinVar SNVs, ~80 k (25%) aligned perfectly to the reference genome (hg38.fa) after validation. The remaining variants likely represent assembly or coordinate mismatches.\n",
    "# I'm going to try NCBI's GRCh38 reference instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c1883-3c9f-44b7-a205-64c409758c6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NCBI GRCh38 (RefSeq) — primary assembly FASTA\n",
    "# This file includes chromosomes and many scaffolds; we will auto-detect the\n",
    "# primary chromosomes by parsing headers ('chromosome 1', ..., 'X', 'Y', 'mitochondrion').\n",
    "\n",
    "import os, urllib.request, gzip, shutil, pathlib\n",
    "\n",
    "REF_DIR = os.path.join(\".\", \"ref\")\n",
    "os.makedirs(REF_DIR, exist_ok=True)\n",
    "\n",
    "# RefSeq assembly (p14 as of writing) — update URL if needed later\n",
    "NCBI_URL = (\"https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/\"\n",
    "            \"GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.fna.gz\")\n",
    "ncbi_gz   = os.path.join(REF_DIR, \"GRCh38.p14_genomic.fna.gz\")\n",
    "ncbi_fa   = os.path.join(REF_DIR, \"GRCh38.p14_genomic.fna\")\n",
    "\n",
    "def _dl(url, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"Downloading {url} -> {dest}\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "    else:\n",
    "        print(f\"Exists: {dest}\")\n",
    "\n",
    "_dl(NCBI_URL, ncbi_gz)\n",
    "\n",
    "if not os.path.exists(ncbi_fa):\n",
    "    print(f\"Unzipping {ncbi_gz} -> {ncbi_fa} (this can take a few minutes)\")\n",
    "    with gzip.open(ncbi_gz, \"rb\") as f_in, open(ncbi_fa, \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "else:\n",
    "    print(f\"Exists: {ncbi_fa}\")\n",
    "\n",
    "print(\"NCBI FASTA ready:\", os.path.exists(ncbi_fa), \"| size (GB) ~\", round(os.path.getsize(ncbi_fa)/1e9, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b1de9-a968-472a-8071-2af66b3e3a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "fa_path = Path(ncbi_fa)\n",
    "assert fa_path.exists(), \"NCBI FASTA not found — run the previous cell first.\"\n",
    "\n",
    "# We'll scan headers to discover accessions and their chromosome names\n",
    "chrom_to_acc = {}   # e.g., {'1': 'NC_000001.11', '2': 'NC_000002.12', ..., 'MT': 'NC_012920.1'}\n",
    "\n",
    "want = {str(i) for i in range(1,23)} | {\"X\",\"Y\",\"MT\"}  # target set\n",
    "\n",
    "header_re = re.compile(r\"^>(\\S+).+?(chromosome\\s+([0-9XY]{1,2})|mitochondrion)\", re.IGNORECASE)\n",
    "\n",
    "with open(fa_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        if not line.startswith(\">\"):\n",
    "            continue\n",
    "        m = header_re.search(line)\n",
    "        if not m:\n",
    "            continue\n",
    "        acc = m.group(1)\n",
    "        chrom_label = m.group(3)\n",
    "        if chrom_label:\n",
    "            key = chrom_label.upper()\n",
    "        else:\n",
    "            # If 'mitochondrion' matched\n",
    "            key = \"MT\"\n",
    "        if key in want and key not in chrom_to_acc:\n",
    "            chrom_to_acc[key] = acc\n",
    "\n",
    "print(\"Discovered chromosome→accession mapping:\")\n",
    "for k in sorted(chrom_to_acc, key=lambda x: (x not in {\"X\",\"Y\",\"MT\"}, x if x.isdigit() else 100)):\n",
    "    print(f\"  {k:>2} -> {chrom_to_acc[k]}\")\n",
    "\n",
    "missing = want - set(chrom_to_acc.keys())\n",
    "if missing:\n",
    "    print(\"WARNING: Did not find entries for:\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda4c594-50fa-435a-99a7-d9ec8308f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chrom_to_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(chrom)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chrom_to_acc\u001b[38;5;241m.\u001b[39mget(key)\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCBI_SEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCHROM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_ncbi_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCHROM\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCBI_SEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRows with missing NCBI mapping:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCBI_SEQ\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:4943\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4810\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4816\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4817\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4934\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4937\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4941\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mto_ncbi_name\u001b[0;34m(chrom)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(chrom)\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchrom_to_acc\u001b[49m\u001b[38;5;241m.\u001b[39mget(key)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chrom_to_acc' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"./data\")\n",
    "src_csv  = os.path.join(DATA_DIR, \"clinvar_snvs_clean.csv\")\n",
    "assert os.path.exists(src_csv), f\"Missing: {src_csv} (run the VCF parsing step first).\"\n",
    "\n",
    "df = pd.read_csv(src_csv, dtype=str)\n",
    "# Coerce numerics\n",
    "df[\"POS\"] = pd.to_numeric(df[\"POS\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"LABEL\"] = pd.to_numeric(df[\"LABEL\"], errors=\"coerce\").astype(\"Int8\")\n",
    "\n",
    "def to_ncbi_name(chrom: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Convert ClinVar CHROM ('1'..'22','X','Y','MT') to NCBI accession using parsed map.\n",
    "    Returns accession string like 'NC_000001.11' or None if unavailable.\n",
    "    \"\"\"\n",
    "    if chrom is None:\n",
    "        return None\n",
    "    key = str(chrom).strip().upper()\n",
    "    return chrom_to_acc.get(key)\n",
    "\n",
    "df[\"NCBI_SEQ\"] = df[\"CHROM\"].apply(to_ncbi_name)\n",
    "print(df[[\"CHROM\",\"NCBI_SEQ\"]].head())\n",
    "print(\"Rows with missing NCBI mapping:\", df[\"NCBI_SEQ\"].isna().sum())\n",
    "df = df.dropna(subset=[\"NCBI_SEQ\",\"POS\",\"REF\",\"ALT\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd4dfcd-3367-415b-be28-25f1e2c68087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fa_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m FLANK \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m     \u001b[38;5;66;03m# adjust (e.g., 50/100/200) as you wish\u001b[39;00m\n\u001b[1;32m      5\u001b[0m MAX_ROWS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# set to small int for quick test, None for all\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m fa_ncbi \u001b[38;5;241m=\u001b[39m Fasta(\u001b[38;5;28mstr\u001b[39m(\u001b[43mfa_path\u001b[49m), as_raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, build_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfetch_windows_ncbi\u001b[39m(row, flank\u001b[38;5;241m=\u001b[39mFLANK):\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Extract ref/alt windows from NCBI GRCh38 using accession names.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Validates that REF matches the FASTA at the center position.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fa_path' is not defined"
     ]
    }
   ],
   "source": [
    "from pyfaidx import Fasta\n",
    "import numpy as np\n",
    "\n",
    "FLANK = 100     # adjust (e.g., 50/100/200) as you wish\n",
    "MAX_ROWS = None # set to small int for quick test, None for all\n",
    "\n",
    "fa_ncbi = Fasta(str(fa_path), as_raw=True, build_index=True)\n",
    "\n",
    "def fetch_windows_ncbi(row, flank=FLANK):\n",
    "    \"\"\"\n",
    "    Extract ref/alt windows from NCBI GRCh38 using accession names.\n",
    "    Validates that REF matches the FASTA at the center position.\n",
    "    \"\"\"\n",
    "    acc = row[\"NCBI_SEQ\"]\n",
    "    pos = int(row[\"POS\"])   # 1-based\n",
    "    ref = str(row[\"REF\"]).upper()\n",
    "    alt = str(row[\"ALT\"]).upper()\n",
    "\n",
    "    start = max(1, pos - flank)\n",
    "    end   = pos + flank\n",
    "\n",
    "    try:\n",
    "        window = fa_ncbi[acc][start:end]\n",
    "    except KeyError:\n",
    "        return None, None\n",
    "\n",
    "    window = str(window).upper()\n",
    "    center_idx = pos - start\n",
    "    if center_idx < 0 or center_idx >= len(window):\n",
    "        return None, None\n",
    "\n",
    "    if window[center_idx] != ref:\n",
    "        return None, None\n",
    "\n",
    "    alt_window = window[:center_idx] + alt + window[center_idx+1:]\n",
    "    return window, alt_window\n",
    "\n",
    "work_df = df if MAX_ROWS is None else df.head(MAX_ROWS).copy()\n",
    "\n",
    "ref_windows, alt_windows = [], []\n",
    "skipped = 0\n",
    "for _, row in work_df.iterrows():\n",
    "    r, a = fetch_windows_ncbi(row, FLANK)\n",
    "    if r is None or a is None:\n",
    "        ref_windows.append(np.nan)\n",
    "        alt_windows.append(np.nan)\n",
    "        skipped += 1\n",
    "    else:\n",
    "        ref_windows.append(r)\n",
    "        alt_windows.append(a)\n",
    "\n",
    "work_df[\"ref_seq\"] = ref_windows\n",
    "work_df[\"alt_seq\"] = alt_windows\n",
    "work_df = work_df.dropna(subset=[\"ref_seq\", \"alt_seq\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Built windows for {len(work_df)} variants; skipped {skipped} due to reference mismatches or contigs.\")\n",
    "print(work_df[[\"CHROM\",\"NCBI_SEQ\",\"POS\",\"REF\",\"ALT\",\"LABEL\",\"ref_seq\",\"alt_seq\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440061f9-6081-4e04-8c8d-b27caa609b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_csv_ncbi = os.path.join(DATA_DIR, f\"clinvar_seq_pairs_ncbi_flank{FLANK}.csv\")\n",
    "work_df.to_csv(out_csv_ncbi, index=False)\n",
    "print(\"Saved:\", out_csv_ncbi, \"| rows:\", len(work_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85319786-2568-4ab3-b69b-c9d069a1c02d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded rows: 79825\n",
      "CHROM               object\n",
      "POS                  Int64\n",
      "REF                 object\n",
      "ALT                 object\n",
      "CLNSIG              object\n",
      "CLNREV              object\n",
      "GENEINFO            object\n",
      "LABEL                 Int8\n",
      "NCBI_SEQ            object\n",
      "ref_seq     string[python]\n",
      "alt_seq     string[python]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>CLNSIG</th>\n",
       "      <th>CLNREV</th>\n",
       "      <th>GENEINFO</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>NCBI_SEQ</th>\n",
       "      <th>ref_seq</th>\n",
       "      <th>alt_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>930204</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Benign</td>\n",
       "      <td>criteria_provided,_multiple_submitters,_no_con...</td>\n",
       "      <td>SAMD11:148398</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCA...</td>\n",
       "      <td>CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>930248</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>Likely_benign</td>\n",
       "      <td>criteria_provided,_multiple_submitters,_no_con...</td>\n",
       "      <td>SAMD11:148398</td>\n",
       "      <td>0</td>\n",
       "      <td>NC_000001.11</td>\n",
       "      <td>CACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGC...</td>\n",
       "      <td>CACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHROM     POS REF ALT         CLNSIG  \\\n",
       "0     1  930204   G   A         Benign   \n",
       "1     1  930248   G   A  Likely_benign   \n",
       "\n",
       "                                              CLNREV       GENEINFO  LABEL  \\\n",
       "0  criteria_provided,_multiple_submitters,_no_con...  SAMD11:148398      0   \n",
       "1  criteria_provided,_multiple_submitters,_no_con...  SAMD11:148398      0   \n",
       "\n",
       "       NCBI_SEQ                                            ref_seq  \\\n",
       "0  NC_000001.11  CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCA...   \n",
       "1  NC_000001.11  CACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGC...   \n",
       "\n",
       "                                             alt_seq  \n",
       "0  CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCA...  \n",
       "1  CACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGC...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for DNABERT fine-tuning\n",
    "# Config and Load sequence pairs\n",
    "import os, pandas as pd\n",
    "\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"./data\")\n",
    "FLANK = 100\n",
    "K = 6\n",
    "\n",
    "src_csv = os.path.join(DATA_DIR, f\"clinvar_seq_pairs_ncbi_flank{FLANK}.csv\")\n",
    "assert os.path.exists(src_csv), f\"Missing: {src_csv}\"\n",
    "\n",
    "# Read everything as string first; prevents DtypeWarning\n",
    "df = pd.read_csv(src_csv, dtype=str, low_memory=False)\n",
    "\n",
    "# Clean stray index cols if present\n",
    "for c in (\"Unnamed: 0\", \"index\"):\n",
    "    if c in df.columns:\n",
    "        df = df.drop(columns=[c])\n",
    "\n",
    "# Coerce numeric columns (nullable dtypes keep NaN if any)\n",
    "if \"POS\" in df.columns:\n",
    "    df[\"POS\"] = pd.to_numeric(df[\"POS\"], errors=\"coerce\").astype(\"Int64\")\n",
    "if \"LABEL\" in df.columns:\n",
    "    df[\"LABEL\"] = pd.to_numeric(df[\"LABEL\"], errors=\"coerce\").astype(\"Int8\")\n",
    "\n",
    "# Make sure sequence/text columns are strings\n",
    "for c in (\"ref_seq\", \"alt_seq\"):\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "\n",
    "df = df.dropna(subset=[\"alt_seq\", \"ref_seq\", \"LABEL\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Loaded rows:\", len(df))\n",
    "print(df.dtypes)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2923bec6-c522-44c9-99e9-d4d1d24bcdc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGCCTGCCGCCCGGAACCTGAAGAAGGAGCGAACTCCCAGCTTCTCTGCCAGCGATGGTGACAGCGACGGGAGTGGCCCCACCTGTGGGCGGCGGCCAGGCTTGAAGCAGGAG\n",
      "CCCACCTTCCTCTCCTCCTGCCCCACCTTCCTCTCCTCCTGCCCCACCAGAACCGGGGGCGGCTGGCAGACAAGAGGACAGTCGCCCTGCCTGCCGCCCGAAACCTGAAGAAGGAGCGAACTCCCAGCTTCTCTGCCAGCGATGGTGACAGCGACGGGAGTGGCCCCACCTGTGGGCGGCGGCCAGGCTTGAAGCAGGAG\n"
     ]
    }
   ],
   "source": [
    "# Verifying no whitespace in sequences. Just Jupyter formatting\n",
    "print(df[\"ref_seq\"].iloc[0])\n",
    "print(df[\"alt_seq\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326818ba-bc8c-43da-b7d9-7dea0aa4312f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# k-mer Utilities\n",
    "import re\n",
    "\n",
    "VALID = set(\"ACGT\")\n",
    "\n",
    "def clean_seq(seq: str) -> str:\n",
    "    \"\"\"Uppercase and replace any non-ACGT with 'A' (simple, fast).\"\"\"\n",
    "    s = str(seq).upper()\n",
    "    return \"\".join(ch if ch in VALID else \"A\" for ch in s)\n",
    "\n",
    "def kmerize(seq: str, k: int = 6) -> str:\n",
    "    \"\"\"Return space-separated overlapping k-mers (DNABERT input).\"\"\"\n",
    "    s = clean_seq(seq)\n",
    "    if len(s) < k:\n",
    "        return \"\"  # will be dropped later\n",
    "    return \" \".join(s[i:i+k] for i in range(len(s) - k + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "091965a6-941f-4ec0-929a-a1e1330b9214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows with too-short sequences for k=6.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>text_alt_k6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>930204</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>CCCACC CCACCT CACCTT ACCTTC CCTTCC CTTCCT TTCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>930248</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>CACCAG ACCAGA CCAGAA CAGAAC AGAACC GAACCG AACC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CHROM     POS REF ALT  LABEL  \\\n",
       "0     1  930204   G   A      0   \n",
       "1     1  930248   G   A      0   \n",
       "\n",
       "                                         text_alt_k6  \n",
       "0  CCCACC CCACCT CACCTT ACCTTC CCTTCC CTTCCT TTCC...  \n",
       "1  CACCAG ACCAGA CCAGAA CAGAAC AGAACC GAACCG AACC...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Built DNABERT text columns (ALT Baseline + optional REF)\n",
    "# ALT-only baseline (recommended first experiment)\n",
    "df[\"text_alt_k6\"] = df[\"alt_seq\"].map(lambda s: kmerize(s, k=K))\n",
    "\n",
    "# (Optional) REF text as well, if you plan paired experiments later\n",
    "df[\"text_ref_k6\"] = df[\"ref_seq\"].map(lambda s: kmerize(s, k=K))\n",
    "\n",
    "# Drop any rows where k-merization failed (too short, etc.)\n",
    "before = len(df)\n",
    "df = df[(df[\"text_alt_k6\"].str.len() > 0)]\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after} rows with too-short sequences for k={K}.\")\n",
    "df[[\"CHROM\",\"POS\",\"REF\",\"ALT\",\"LABEL\",\"text_alt_k6\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8b8880-4ed1-4238-bc41-880a2198dadb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "   ./data/prepared_k6_alt_only_all.csv (rows=79825)\n",
      "   ./data/prepared_k6_alt_only_train.csv (rows=63860)\n",
      "   ./data/prepared_k6_alt_only_val.csv (rows=15965)\n",
      "Label balance (all):\n",
      " LABEL\n",
      "0    0.836\n",
      "1    0.164\n",
      "Name: proportion, dtype: Float64\n"
     ]
    }
   ],
   "source": [
    "# Stratified train/val split and save CSVs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "keep_cols = [\"CHROM\",\"POS\",\"REF\",\"ALT\",\"LABEL\",\"text_alt_k6\",\"text_ref_k6\",\"ref_seq\",\"alt_seq\"]\n",
    "prepared = df[keep_cols].copy()\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    prepared,\n",
    "    test_size=0.2,\n",
    "    stratify=prepared[\"LABEL\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "prep_all  = os.path.join(DATA_DIR, f\"prepared_k{K}_alt_only_all.csv\")\n",
    "prep_tr   = os.path.join(DATA_DIR, f\"prepared_k{K}_alt_only_train.csv\")\n",
    "prep_val  = os.path.join(DATA_DIR, f\"prepared_k{K}_alt_only_val.csv\")\n",
    "\n",
    "prepared.to_csv(prep_all, index=False)\n",
    "train_df.to_csv(prep_tr, index=False)\n",
    "val_df.to_csv(prep_val, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", prep_all, f\"(rows={len(prepared)})\")\n",
    "print(\"  \", prep_tr,  f\"(rows={len(train_df)})\")\n",
    "print(\"  \", prep_val, f\"(rows={len(val_df)})\")\n",
    "print(\"Label balance (all):\\n\", prepared[\"LABEL\"].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26b7d448-73e0-4dee-a3f4-d53596b12411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c133c0552f8d4c8b86c5566cf11713a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Hugging Face Login\n",
    "# Only needed if your environment blocks anonymous HF downloads\n",
    "# Get a token from https://huggingface.co/settings/tokens\n",
    "# and paste it when prompted.\n",
    "from huggingface_hub import login\n",
    "try:\n",
    "    login()  # or login(token=\"hf_...\") to pass programmatically\n",
    "except Exception as e:\n",
    "    print(\"HF login skipped or not required:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff12c723-b389-4f5e-8bf0-2ff68bbc4398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc9084d934d44a1db44d9259cfb28b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825367daa6f644a0bfeec08718724a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fc794fa5414c5c8e0f1bbbec4d8935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e622922f5c49d3a02e675ee3ab205e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer from: zhihan1996/DNA_bert_6\n",
      "Tokenized input_ids shape: torch.Size([1, 512])\n",
      "First 10 tokens: [2, 2703, 2606, 2218, 667, 2655, 2414, 1451, 1694, 2667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load DNABERT tokenizer \n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_CANDIDATES = [\n",
    "    \"zhihan1996/DNA_bert_6\",     # official DNABERT (k=6)\n",
    "    \"armheb/DNA_bert_6\",         # public mirror\n",
    "    # add more fallbacks here if needed\n",
    "]\n",
    "\n",
    "tok = None\n",
    "last_err = None\n",
    "for mid in MODEL_CANDIDATES:\n",
    "    try:\n",
    "        tok = AutoTokenizer.from_pretrained(mid, use_fast=False)  # DNABERT uses a classic BertTokenizer\n",
    "        MODEL_NAME = mid\n",
    "        print(\"Loaded tokenizer from:\", mid)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        print(f\"Failed to load {mid}: {e}\")\n",
    "\n",
    "if tok is None:\n",
    "    raise last_err\n",
    "\n",
    "# Your existing sanity check\n",
    "sample = prepared[\"text_alt_k6\"].iloc[0]\n",
    "enc = tok(sample, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "print(\"Tokenized input_ids shape:\", enc[\"input_ids\"].shape)\n",
    "print(\"First 10 tokens:\", enc[\"input_ids\"][0, :10].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0b3e4-b5ca-4ce1-aff4-103ba9ae0555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's train. \n",
    "# 1. Baseline full fine-tune\n",
    "# 2. Weighted Loss (to handle the 83.6/16.4 class imbalance. May address this later\n",
    "# 3. LoRA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249e1d4-04f3-4897-927c-a099346fe87f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-time fixing packages\n",
    "#%pip install -U \"transformers>=4.44.2\" \"accelerate>=0.34.2\" \"peft>=0.13.2\" \"datasets>=2.20\"\n",
    "\n",
    "#import transformers, torch\n",
    "#print(\"Transformers:\", transformers.__version__)\n",
    "#print(\"Torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ea195-4524-4d8f-89ff-d92733df7900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time fix for transformers version\n",
    "\n",
    "#%pip uninstall -y transformers\n",
    "#%pip install \"transformers==4.44.2\"  # known-good, definitely has evaluation_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81918894-6ea8-4b64-b31f-d60403fb1d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "import inspect\n",
    "\"evaluation_strategy\" in inspect.signature(TrainingArguments.__init__).parameters\n",
    "# should print: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3531276-67c2-4087-af11-821624158d58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at zhihan1996/DNA_bert_6 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7983' max='7983' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7983/7983 34:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.380500</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0.797503</td>\n",
       "      <td>0.852928</td>\n",
       "      <td>0.612745</td>\n",
       "      <td>0.285823</td>\n",
       "      <td>0.389813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'auc': 0.7975033924852966,\n",
       " 'accuracy': 0.8529282806138427,\n",
       " 'precision': 0.6127450980392157,\n",
       " 'recall': 0.2858231707317073,\n",
       " 'f1': 0.3898128898128898}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Baseline full fine-tune\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "MODEL_NAME = mid  # from the tokenizer cell you just ran\n",
    "tokenizer = tok\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "class KmerTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col=\"text_alt_k6\", label_col=\"LABEL\", max_length=512):\n",
    "        self.texts = df[text_col].tolist()\n",
    "        self.labels = df[label_col].astype(int).tolist()\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_ds = KmerTextDataset(train_df)\n",
    "val_ds   = KmerTextDataset(val_df)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def compute_classification_metrics(y_true, y_prob):\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    return {\"auc\": auc, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "def hf_compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:,1].numpy()\n",
    "    return compute_classification_metrics(labels, probs)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./runs/dnabert_fullft\",\n",
    "    num_train_epochs=1,                 # start with 1 for smoke test; then 3–5\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"auc\",        # since your compute_metrics returns 'auc'\n",
    "    greater_is_better=True,\n",
    "    report_to=[],                       # avoids wandb/autologging surprises\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=hf_compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()   # <-- run when ready\n",
    "preds = trainer.predict(val_ds)\n",
    "y_prob = torch.softmax(torch.tensor(preds.predictions), dim=1)[:,1].numpy()\n",
    "metrics = compute_classification_metrics(preds.label_ids, y_prob); metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe2f4bec-fc0a-4fa8-abe8-c6e5fd27f51a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39915' max='39915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39915/39915 2:53:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.355586</td>\n",
       "      <td>0.836388</td>\n",
       "      <td>0.857626</td>\n",
       "      <td>0.584497</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>0.516486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.332220</td>\n",
       "      <td>0.871593</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.713059</td>\n",
       "      <td>0.443216</td>\n",
       "      <td>0.546651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.261400</td>\n",
       "      <td>0.432063</td>\n",
       "      <td>0.880534</td>\n",
       "      <td>0.884435</td>\n",
       "      <td>0.712958</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.585673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.220900</td>\n",
       "      <td>0.464837</td>\n",
       "      <td>0.881413</td>\n",
       "      <td>0.886502</td>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.535061</td>\n",
       "      <td>0.607792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.532064</td>\n",
       "      <td>0.878959</td>\n",
       "      <td>0.886564</td>\n",
       "      <td>0.693295</td>\n",
       "      <td>0.555640</td>\n",
       "      <td>0.616882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>eval_auc</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836388</td>\n",
       "      <td>0.516486</td>\n",
       "      <td>0.857626</td>\n",
       "      <td>0.584497</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>0.355586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.871593</td>\n",
       "      <td>0.546651</td>\n",
       "      <td>0.879173</td>\n",
       "      <td>0.713059</td>\n",
       "      <td>0.443216</td>\n",
       "      <td>0.332220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.880534</td>\n",
       "      <td>0.585673</td>\n",
       "      <td>0.884435</td>\n",
       "      <td>0.712958</td>\n",
       "      <td>0.496951</td>\n",
       "      <td>0.432063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.881413</td>\n",
       "      <td>0.607792</td>\n",
       "      <td>0.886502</td>\n",
       "      <td>0.703407</td>\n",
       "      <td>0.535061</td>\n",
       "      <td>0.464837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.878959</td>\n",
       "      <td>0.616882</td>\n",
       "      <td>0.886564</td>\n",
       "      <td>0.693295</td>\n",
       "      <td>0.555640</td>\n",
       "      <td>0.532064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  eval_auc   eval_f1  eval_accuracy  eval_precision  eval_recall  \\\n",
       "0    1.0  0.836388  0.516486       0.857626        0.584497     0.462652   \n",
       "1    2.0  0.871593  0.546651       0.879173        0.713059     0.443216   \n",
       "2    3.0  0.880534  0.585673       0.884435        0.712958     0.496951   \n",
       "3    4.0  0.881413  0.607792       0.886502        0.703407     0.535061   \n",
       "4    5.0  0.878959  0.616882       0.886564        0.693295     0.555640   \n",
       "\n",
       "   eval_loss  \n",
       "0   0.355586  \n",
       "1   0.332220  \n",
       "2   0.432063  \n",
       "3   0.464837  \n",
       "4   0.532064  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-checkpoint metrics: {'auc': 0.8814127141756296, 'accuracy': 0.8865017225180082, 'precision': 0.7034068136272545, 'recall': 0.5350609756097561, 'f1': 0.6077922077922078}\n",
      "Saved per-epoch metrics -> ./runs/dnabert_fullft_es/val_metrics_by_epoch.csv\n"
     ]
    }
   ],
   "source": [
    "# === Early-stopping training run (max 5 epochs) ===\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, TrainerCallback\n",
    "import torch, pandas as pd\n",
    "\n",
    "# Callback to capture per-epoch metrics cleanly\n",
    "class MetricHistory(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.rows = []\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics is None: \n",
    "            return\n",
    "        row = {\"epoch\": state.epoch}\n",
    "        # keep the common ones if present\n",
    "        for k in [\"eval_auc\",\"eval_f1\",\"eval_accuracy\",\"eval_precision\",\"eval_recall\",\"eval_loss\"]:\n",
    "            if k in metrics: row[k] = metrics[k]\n",
    "        self.rows.append(row)\n",
    "\n",
    "hist = MetricHistory()\n",
    "\n",
    "training_args_es = TrainingArguments(\n",
    "    output_dir=\"./runs/dnabert_fullft_es\",\n",
    "    num_train_epochs=5,                 # upper bound\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"auc\",\n",
    "    greater_is_better=True,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=100,\n",
    "    report_to=[],\n",
    ")\n",
    "\n",
    "trainer_es = Trainer(\n",
    "    model=model,                        # continues from your current model (after 1 epoch)\n",
    "    args=training_args_es,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=hf_compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=2,          # stop after 2 epochs w/o sufficient AUC gain\n",
    "            early_stopping_threshold=0.002      # min AUC improvement to count as “better”\n",
    "        ),\n",
    "        hist\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Train with early stopping\n",
    "train_output = trainer_es.train()\n",
    "\n",
    "# Show per-epoch validation metrics\n",
    "df_hist = pd.DataFrame(hist.rows).sort_values(\"epoch\")\n",
    "display(df_hist)\n",
    "\n",
    "# Evaluate the best checkpoint on the validation set\n",
    "preds_es = trainer_es.predict(val_ds)\n",
    "y_prob_es = torch.softmax(torch.tensor(preds_es.predictions), dim=1)[:,1].numpy()\n",
    "metrics_es = compute_classification_metrics(preds_es.label_ids, y_prob_es)\n",
    "print(\"Best-checkpoint metrics:\", metrics_es)\n",
    "\n",
    "# (Optional) save the history for your report\n",
    "df_hist.to_csv(\"./runs/dnabert_fullft_es/val_metrics_by_epoch.csv\", index=False)\n",
    "print(\"Saved per-epoch metrics -> ./runs/dnabert_fullft_es/val_metrics_by_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f64206b-3595-4b5c-811a-dc16d4ecfd34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved best model from Epoch 4 → ./runs/dnabert_fullft_es/best_model\n"
     ]
    }
   ],
   "source": [
    "# Save Epoch 4 or model with best AUC due to class imbalance \n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "best_ckpt = \"./runs/dnabert_fullft_es/checkpoint-31932\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(best_ckpt)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(best_ckpt)\n",
    "\n",
    "save_dir = \"./runs/dnabert_fullft_es/best_model\"\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"✅ Saved best model from Epoch 4 → {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b15817e-2ed1-4704-bc12-d3fdb47a8ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics (reloaded model):\n",
      "  auc: 0.881419\n",
      "  accuracy: 0.886502\n",
      "  precision: 0.703407\n",
      "  recall: 0.535061\n",
      "  f1: 0.607792\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Reload best model and re-evaluate on validation CSV ---\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_recall_fscore_support, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1) Paths – EDIT if needed\n",
    "DATA_DIR = os.environ.get(\"DATA_DIR\", \"./data\")\n",
    "VAL_CSV  = os.path.join(DATA_DIR, \"prepared_k6_alt_only_val.csv\")\n",
    "BEST_DIR = \"./runs/dnabert_fullft_es/best_model\"   # or \"./runs/dnabert_fullft_es/checkpoint-31932\"\n",
    "\n",
    "assert os.path.exists(VAL_CSV), f\"Missing val CSV: {VAL_CSV}\"\n",
    "assert os.path.isdir(BEST_DIR), f\"Missing model dir: {BEST_DIR}\"\n",
    "\n",
    "# 2) Reload tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(BEST_DIR, use_fast=False)  # DNABERT tokenizer is classic (non-fast)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BEST_DIR)\n",
    "model.eval()  # put in inference mode\n",
    "\n",
    "# (Optional) \"Freeze\" weights if you want to guarantee no grads by accident:\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 3) Validation dataset wrapper (must match how we trained)\n",
    "class KmerTextDataset(Dataset):\n",
    "    def __init__(self, df, text_col=\"text_alt_k6\", label_col=\"LABEL\", max_length=512):\n",
    "        self.texts = df[text_col].astype(str).tolist()\n",
    "        self.labels = df[label_col].astype(int).tolist()\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        enc = tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "val_ds = KmerTextDataset(val_df)\n",
    "\n",
    "# 4) Metrics\n",
    "def compute_classification_metrics(y_true, y_prob):\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    return {\"auc\": auc, \"accuracy\": acc, \"precision\": prec, \"recall\": rec, \"f1\": f1}\n",
    "\n",
    "def hf_compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=1)[:, 1].numpy()\n",
    "    return compute_classification_metrics(labels, probs)\n",
    "\n",
    "# 5) Use a lightweight Trainer for evaluation\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./runs/tmp_eval\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_drop_last=False,\n",
    "    report_to=[],  # no logging integrations\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model, args=args, tokenizer=tokenizer)\n",
    "\n",
    "# Predict on val set\n",
    "preds = trainer.predict(val_ds)\n",
    "y_prob = torch.softmax(torch.tensor(preds.predictions), dim=1)[:, 1].numpy()\n",
    "metrics = compute_classification_metrics(preds.label_ids, y_prob)\n",
    "print(\"Validation metrics (reloaded model):\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"  {k}: {v:.6f}\")\n",
    "\n",
    "# 6) (Optional) ROC curve\n",
    "fpr, tpr, _ = roc_curve(preds.label_ids, y_prob)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(fpr, tpr, lw=2)\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC – Reloaded Best Model\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710fd218-3ea7-4630-b00a-0a21fa84e4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m134",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m134"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
